# Image_captioning_with_Attention
- The model addresses the task of automatically generating captions for images by attending to different regions of the image while generating each word of the caption.

- **Resnet** model is used for encoding the images.
- **LSTM** cells with attention are used as decoder for generating the caption of the image.

- Link to the folder that contains FLickr8k dataset, JSON format of coco and flickr8k datasets [link](https://drive.google.com/drive/folders/1QDv7--xZqgVX-wtsImcEoBwvY5-ctFJa?usp=drive_link)

## Model
![](model.png)
## Results
  ![](predictions/alphas_time_step_14.jpg)
  ![](predictions/alphas_img_6.jpg)
  ![](predictions/alphas_img_3.jpg)
  ![](predictions/alphas_img_4.jpg)
  ![](predictions/alphas_img_5.jpg)
  ![](predictions/alphas_img_2.jpg)

  
